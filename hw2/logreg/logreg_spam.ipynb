{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-4.8631135] [[ -2.74146024e-02  -2.25297686e-01   1.21840881e-01   2.29362960e+00\n",
      "    2.70425727e-01   2.32851135e-01   9.28595398e-01   2.95200203e-01\n",
      "    1.62205924e-01   6.78259065e-02  -8.32603793e-02  -1.60373348e-01\n",
      "   -4.72247998e-02   1.07676963e-02   1.87903772e-01   8.19771791e-01\n",
      "    5.09529031e-01   3.98710853e-02   2.67729669e-01   3.47047290e-01\n",
      "    2.60498935e-01   3.64605723e-01   7.25019849e-01   1.96728229e-01\n",
      "   -3.15395711e+00  -4.03133853e-01  -1.25451036e+01  -6.16576365e-02\n",
      "   -1.56114580e+00  -5.51430802e-02  -3.00823299e-02   4.07263819e-01\n",
      "   -3.68156523e-01  -1.43611920e+00  -5.87182204e-01   4.44294622e-01\n",
      "    4.23159806e-02  -1.56897100e-01  -4.55330675e-01  -1.02250213e-01\n",
      "   -3.54273318e+00  -1.72944427e+00  -4.37529503e-01  -1.05999940e+00\n",
      "   -9.18599253e-01  -1.75490289e+00  -1.67475810e-01  -9.56875762e-01\n",
      "   -3.65653449e-01  -1.36535596e-01  -6.58692636e-02   2.06714075e-01\n",
      "    1.70694415e+00   1.21460288e+00  -3.35270344e-01   1.56141577e+00\n",
      "    3.68775509e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.9296875\n",
      "best_lambda =  1.1\n",
      "Coefficients =  [-4.06889361] [[ -1.63195481e-01  -5.64070134e-02  -1.16367848e-01   6.41607135e-01\n",
      "    4.56051918e-01   2.57862053e-01   9.15766194e-01   4.54527814e-01\n",
      "    9.97243051e-02   1.40317756e-01  -9.71457337e-02  -1.99207007e-01\n",
      "   -3.07496210e-01   2.22418777e-01   3.08691418e-01   5.18969168e-01\n",
      "    5.25598337e-01  -7.84135179e-02   1.17650271e-01   2.92059605e-01\n",
      "    2.14551068e-01   1.52360469e-01   5.85348121e-01   5.42188071e-01\n",
      "   -1.19378669e+00  -2.29739370e-02  -2.91545799e+00   1.48305087e-01\n",
      "   -2.30401141e-01   3.11129672e-02   2.68420894e-01   6.50380795e-01\n",
      "   -1.78813606e-01   1.22582489e+00  -4.53841712e-01   4.98496527e-01\n",
      "   -3.85589532e-01   2.04064578e-01  -2.82749321e-01   2.47963377e-03\n",
      "   -4.31016023e-01  -8.20242279e-01  -5.42892884e-01  -7.60253743e-01\n",
      "   -4.14005244e-01  -9.03572696e-01  -6.80247584e-02  -6.91498498e-01\n",
      "   -3.40559939e-01  -1.17487195e-01   1.41000349e-01   7.67218516e-01\n",
      "    1.30004324e+00   9.13621344e-03   7.13624404e-01   6.36097110e-02\n",
      "    3.27781112e-01]]\n",
      "Accuracy on set aside test set for  logt  =  0.942708333333\n",
      "best_lambda =  1.1\n",
      "Coefficients =  [-1.83742964] [[ -1.91463198e-01  -1.66872958e-01  -3.93802023e-01   2.39462779e-01\n",
      "    9.83292893e-01   1.75311415e-01   2.12183419e+00   7.92547596e-01\n",
      "    1.94566579e-01   3.34388296e-01  -2.90824615e-01  -4.20297340e-01\n",
      "   -9.06380382e-01   2.56299856e-01   5.15189474e-01   1.47014136e+00\n",
      "    8.76696476e-01  -8.32760955e-02   2.41264180e-01   5.01801273e-01\n",
      "    7.37046896e-01   1.15518007e+00   9.11195183e-01   1.36902984e+00\n",
      "   -2.35248856e+00  -4.17190307e-01  -3.79772643e+00   6.88337611e-01\n",
      "   -6.07237597e-01  -1.61622832e-01  -9.24671805e-01  -6.04558748e-01\n",
      "   -6.91161481e-01  -3.85638232e-02  -6.71440136e-01   3.52732370e-01\n",
      "   -1.05408408e+00   5.28551480e-01  -7.65306731e-01  -2.46067578e-01\n",
      "   -1.27643951e+00  -1.90613122e+00  -7.90184279e-01  -1.57619158e+00\n",
      "   -7.64312034e-01  -2.22366816e+00  -8.34144234e-02  -1.39371572e+00\n",
      "   -3.06993897e-01   2.00231957e-01  -1.70968577e-01   1.20762876e+00\n",
      "    1.45771409e+00   3.79908690e-02   5.31812831e-04   5.31812831e-04\n",
      "    5.31812831e-04]]\n",
      "Accuracy on set aside test set for  bin  =  0.927734375\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda =  4.6\n",
      "Coefficients =  [-1.59516271] [[-0.01067948 -0.15872477  0.12269003  0.20799068  0.24913974  0.17702943\n",
      "   0.91018616  0.28982048  0.13968958  0.04855421 -0.02304896 -0.13982387\n",
      "  -0.00706923  0.00919878  0.15333741  0.75697191  0.45997344  0.0703777\n",
      "   0.25407797  0.19637165  0.24326439  0.34651883  0.72625286  0.2341258\n",
      "  -2.34097228 -0.35782182 -3.17992043 -0.01076789 -0.3709523   0.          0.\n",
      "   0.         -0.32756926  0.         -0.0613645   0.24255267  0.\n",
      "  -0.11599111 -0.31157456 -0.04378559 -0.23954962 -0.79590992 -0.19067325\n",
      "  -0.56451837 -0.73380684 -1.18118442 -0.08552176 -0.5133779  -0.25640537\n",
      "  -0.13352132 -0.05665199  0.2182394   1.64756852  0.22127163  0.\n",
      "   0.64798334  0.33272107]]\n",
      "Accuracy on set aside test set for  std  =  0.921875\n",
      "best_lambda =  4.6\n",
      "Coefficients =  [ 0.] [[-0.03120732  0.         -0.05816674  0.22615003  0.42843497  0.16469563\n",
      "   0.9382741   0.43640058  0.03391369  0.09004209  0.         -0.18989918\n",
      "  -0.155926    0.15461291  0.06945113  0.50997978  0.48485075  0.\n",
      "   0.08154366  0.1377415   0.20230946  0.13186188  0.54583505  0.53529103\n",
      "  -1.10097492  0.         -1.59330724  0.04171421  0.          0.          0.\n",
      "   0.         -0.05636876  0.          0.          0.33453225 -0.3627049\n",
      "   0.         -0.12795141  0.          0.         -0.57362913 -0.00693751\n",
      "  -0.37708783 -0.34422804 -0.78690997  0.         -0.26099977 -0.05032373\n",
      "   0.          0.          0.75793953  1.31589911  0.          0.57410669\n",
      "   0.14339355  0.17450042]]\n",
      "Accuracy on set aside test set for  logt  =  0.942057291667\n",
      "best_lambda =  3.6\n",
      "Coefficients =  [-0.58672994] [[ 0.          0.         -0.19377464  0.          0.86547469  0.\n",
      "   2.02959988  0.63346902  0.02624421  0.21235269  0.         -0.42164924\n",
      "  -0.68110242  0.          0.          1.31595628  0.76628707  0.\n",
      "   0.11066318  0.12274678  0.63323242  0.73137065  0.6209257   1.18327148\n",
      "  -2.42510886 -0.12385831 -3.73108204  0.          0.          0.          0.\n",
      "   0.         -0.28834204  0.         -0.21940463  0.         -1.01562408\n",
      "   0.         -0.40515853  0.         -0.11540515 -1.69452251 -0.03900722\n",
      "  -1.11009953 -0.68706762 -2.21988587  0.         -1.02550027 -0.12525594\n",
      "   0.07501805  0.          1.14996387  1.5009573   0.         -0.429102\n",
      "  -0.24756774 -0.40432783]]\n",
      "Accuracy on set aside test set for  bin  =  0.92578125\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# No modifications in this script\n",
    "# complete the functions in util.py; then run the script\n",
    "\n",
    "# load the spam data in\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,type,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print \"best_lambda = \", best_lambda\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print \"Coefficients = \", lreg.intercept_,lreg.coef_\n",
    "    predy = lreg.predict(Xt)\n",
    "    print \"Accuracy on set aside test set for \", type, \" = \", np.mean(predy==ytest)\n",
    "\n",
    "print \"L2 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print \"L1 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
